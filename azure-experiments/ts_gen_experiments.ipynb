{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "- Set tracking URI\r\n",
        "- Create experiment\r\n",
        "- Create train and test sets\r\n",
        "- Train while logging metrics and artifacts. \r\n",
        "    - Train script should use mlflow to log model HP values, errors, save final D_init, W, embedding after each epoch\r\n",
        "\r\n",
        "TODO:\r\n",
        "- Modify train.py if necessary\r\n",
        "- Make sure can run train and log parameters with current formulation\r\n",
        "- Run with different sets of hyperparameters"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from rdkit import Chem, Geometry\r\n",
        "\r\n",
        "# load data (don't remove hydrogens and don't sanitise) TODO? functionise this\r\n",
        "reactant_file = \"../create_figs/model_data/train_reactants.sdf\"\r\n",
        "train_r = Chem.SDMolSupplier(reactant_file, removeHs=False, sanitize=False)\r\n",
        "train_r = [r for r in train_r]        \r\n",
        "\r\n",
        "ts_file = \"../create_figs/model_data/train_ts.sdf\"\r\n",
        "train_ts = Chem.SDMolSupplier(ts_file, removeHs=False, sanitize=False)\r\n",
        "train_ts = [ts for ts in train_ts]        \r\n",
        "\r\n",
        "product_file = \"../create_figs/model_data/train_products.sdf\"\r\n",
        "train_p = Chem.SDMolSupplier(product_file, removeHs=False, sanitize=False)\r\n",
        "train_p = [p for p in train_p]        \r\n",
        "\r\n",
        "train_data = list(zip(train_r, train_ts, train_p))\r\n",
        "\r\n",
        "num_train = len(train_data)\r\n",
        "num_valid = int(round(num_train / 8))\r\n",
        "\r\n",
        "# train:val splits\r\n",
        "data_train = train_data[ :num_train - num_valid]\r\n",
        "data_val = train_data[num_train - num_valid: ]"
      ],
      "outputs": [],
      "execution_count": 30,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1621938278627
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "elements = \"HCNO\"\r\n",
        "num_elements = len(elements)\r\n",
        "max_size = 21\r\n",
        "\r\n",
        "def prepare_batch(batch_mols):\r\n",
        "\r\n",
        "    # Initialization\r\n",
        "    size = len(batch_mols)\r\n",
        "    V = np.zeros((size, max_size, num_elements + 1), dtype=np.float32)\r\n",
        "    E = np.zeros((size, max_size, max_size, 3), dtype=np.float32)\r\n",
        "    sizes = np.zeros(size, dtype=np.int32)\r\n",
        "    coordinates = np.zeros((size, max_size, 3), dtype=np.float32)\r\n",
        "\r\n",
        "    # Build atom features\r\n",
        "    for bx in range(size):\r\n",
        "        reactant, ts, product = batch_mols[bx]\r\n",
        "        N_atoms = reactant.GetNumAtoms()\r\n",
        "        sizes[bx] = int(N_atoms)\r\n",
        "\r\n",
        "        # Topological distances matrix\r\n",
        "        MAX_D = 10.\r\n",
        "        D = (Chem.GetDistanceMatrix(reactant) + Chem.GetDistanceMatrix(product)) / 2\r\n",
        "        D[D > MAX_D] = 10.\r\n",
        "\r\n",
        "        D_3D_rbf = np.exp(-((Chem.Get3DDistanceMatrix(reactant) + Chem.Get3DDistanceMatrix(product)) / 2))  # squared\r\n",
        "\r\n",
        "        for i in range(N_atoms):\r\n",
        "            # Edge features\r\n",
        "            for j in range(N_atoms):\r\n",
        "                E[bx, i, j, 2] = D_3D_rbf[i][j]\r\n",
        "                if D[i][j] == 1.:  # if stays bonded\r\n",
        "                    if reactant.GetBondBetweenAtoms(i, j).GetIsAromatic():\r\n",
        "                        E[bx, i, j, 0] = 1.\r\n",
        "                    E[bx, i, j, 1] = 1.\r\n",
        "\r\n",
        "            # Recover coordinates; adapted for all\r\n",
        "            # for k, mol_typ in enumerate([reactant, ts, product]):\r\n",
        "            pos = ts.GetConformer().GetAtomPosition(i)\r\n",
        "            np.asarray([pos.x, pos.y, pos.z])\r\n",
        "            coordinates[bx, i, :] = np.asarray([pos.x, pos.y, pos.z])\r\n",
        "\r\n",
        "            # Node features\r\n",
        "            atom = reactant.GetAtomWithIdx(i)\r\n",
        "            e_ix = elements.index(atom.GetSymbol())\r\n",
        "            V[bx, i, e_ix] = 1.\r\n",
        "            V[bx, i, num_elements] = atom.GetAtomicNum() / 10.\r\n",
        "            # V[bx, i, num_elements + 1] = atom.GetExplicitValence() / 10.\r\n",
        "\r\n",
        "    # print(np.sum(np.square(V)),np.sum(np.square(E)), sizes)\r\n",
        "    batch_dict = {\r\n",
        "        \"nodes\": tf.constant(V),\r\n",
        "        \"edges\": tf.constant(E),\r\n",
        "        \"sizes\": tf.constant(sizes),\r\n",
        "        \"coordinates\": tf.constant(coordinates)\r\n",
        "    }\r\n",
        "    return batch_dict"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/anaconda/envs/tsir-rdkit-env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/anaconda/envs/tsir-rdkit-env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/anaconda/envs/tsir-rdkit-env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/anaconda/envs/tsir-rdkit-env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/anaconda/envs/tsir-rdkit-env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/anaconda/envs/tsir-rdkit-env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/anaconda/envs/tsir-rdkit-env/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/anaconda/envs/tsir-rdkit-env/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/anaconda/envs/tsir-rdkit-env/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/anaconda/envs/tsir-rdkit-env/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/anaconda/envs/tsir-rdkit-env/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/anaconda/envs/tsir-rdkit-env/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ]
        }
      ],
      "execution_count": 18,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1621930311946
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys, os\r\n",
        "import mlflow\r\n",
        "import mlflow.azureml\r\n",
        "\r\n",
        "import azureml.core\r\n",
        "from azureml.core import Workspace\r\n",
        "\r\n",
        "ws = Workspace.from_config()\r\n",
        "\r\n",
        "print(\"SDK version:\", azureml.core.VERSION)\r\n",
        "print(\"MLflow version:\", mlflow.version.VERSION)\r\n",
        "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep = '\\n')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SDK version: 1.28.0\n",
            "MLflow version: 1.17.0\n",
            "ReactionModelling\n",
            "ResearchProj\n",
            "uksouth\n",
            "4ba7b086-969d-41c4-a647-2784cde6af4b\n"
          ]
        }
      ],
      "execution_count": 5,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1621868278150
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.compute import ComputeTarget, AmlCompute\r\n",
        "from azureml.core.compute_target import ComputeTargetException\r\n",
        "\r\n",
        "# choose a name for your CPU cluster\r\n",
        "cpu_cluster_name = \"cpucluster\"\r\n",
        "\r\n",
        "# verify that cluster does not exist already\r\n",
        "try:\r\n",
        "    cpu_cluster = ComputeTarget(workspace = ws, name = cpu_cluster_name)\r\n",
        "    print('Found existing cluster, use it.')\r\n",
        "except ComputeTargetException:\r\n",
        "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_D2_V2',\r\n",
        "                                                           max_nodes=4)\r\n",
        "    cpu_cluster = ComputeTarget.create(ws, cpu_cluster_name, compute_config)\r\n",
        "\r\n",
        "cpu_cluster.wait_for_completion(show_output=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing cluster, use it.\n",
            "Succeeded\n",
            "AmlCompute wait for completion finished\n",
            "\n",
            "Minimum number of nodes requested have been provisioned\n"
          ]
        }
      ],
      "execution_count": 3,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1621856902020
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set tracking URI\r\n",
        "mlflow.set_tracking_uri(ws.get_mlflow_tracking_uri())\r\n",
        "\r\n",
        "# create mlflow experiment\r\n",
        "experiment_name = \"train-tsgen\"\r\n",
        "mlflow.set_experiment(experiment_name)\r\n",
        "\r\n",
        "# create backend config object\r\n",
        "backend_config = {\"COMPUTE\": \"cpucluster\", \"USE_CONDA\": False}"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1621868282301
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# submit run\r\n",
        "remote_mlflow_run = mlflow.projects.run(uri=\".\", \r\n",
        "                                    parameters={\"layers\": 2, \"hidden_size\": 128, \"iterations\": 3, \"batch_size\", 8},\r\n",
        "                                    backend = \"azureml\",\r\n",
        "                                    backend_config = backend_config,\r\n",
        "                                    synchronous=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Class AzureMLProjectBackend: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ExecutionException",
          "evalue": "Could not find main among entry points [] or interpret main as a runnable script. Supported script file extensions: ['.py', '.sh']",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mExecutionException\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/mlflow/_internal/projects.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, project_uri, entry_point, params, version, backend_config, tracking_uri, experiment_id)\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m             \u001b[0mwork_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_and_validate_project\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproject_uri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentry_point\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m             \u001b[0mmlproject\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_project\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwork_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/mlflow/projects/utils.py\u001b[0m in \u001b[0;36mfetch_and_validate_project\u001b[0;34m(uri, version, entry_point, parameters)\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0mproject\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_project_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_project\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwork_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0mproject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_entry_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentry_point\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwork_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/mlflow/projects/_project_spec.py\u001b[0m in \u001b[0;36mget_entry_point\u001b[0;34m(self, entry_point)\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mEntryPoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mentry_point\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcommand\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         raise ExecutionException(\n\u001b[0m\u001b[1;32m    133\u001b[0m             \u001b[0;34m\"Could not find {0} among entry points {1} or interpret {0} as a \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mExecutionException\u001b[0m: Could not find main among entry points [] or interpret main as a runnable script. Supported script file extensions: ['.py', '.sh']",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mExecutionException\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-e9284f825a2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# submit run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m remote_mlflow_run = mlflow.projects.run(uri=\".\", \n\u001b[0m\u001b[1;32m      3\u001b[0m                                     \u001b[0mparameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"alpha\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                     \u001b[0mbackend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"azureml\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                     \u001b[0mbackend_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/mlflow/projects/__init__.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(uri, entry_point, version, parameters, docker_args, experiment_name, experiment_id, backend, backend_config, use_conda, storage_dir, synchronous, run_id)\u001b[0m\n\u001b[1;32m    291\u001b[0m     )\n\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m     submitted_run_obj = _run(\n\u001b[0m\u001b[1;32m    294\u001b[0m         \u001b[0muri\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0mexperiment_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexperiment_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/mlflow/projects/__init__.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(uri, experiment_id, entry_point, version, parameters, docker_args, backend_name, backend_config, use_conda, storage_dir, synchronous)\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mbackend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbackend_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             submitted_run = backend.run(\n\u001b[0m\u001b[1;32m     93\u001b[0m                 \u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m                 \u001b[0mentry_point\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/mlflow/_internal/projects.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, project_uri, entry_point, params, version, backend_config, tracking_uri, experiment_id)\u001b[0m\n\u001b[1;32m    198\u001b[0m             \u001b[0mmlproject\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_project\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwork_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mExecutionException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mExecutionException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0;31m# process mlflow parameters into a format usable for AzureML ScriptRunConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0mcommand_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mExecutionException\u001b[0m: Could not find main among entry points [] or interpret main as a runnable script. Supported script file extensions: ['.py', '.sh']"
          ]
        }
      ],
      "execution_count": 33,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": true
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# view metrics and artifacts in your workspace\r\n",
        "run.get_metrics()\r\n",
        "\r\n",
        "# once run complete\r\n",
        "# the model folder produced from the run is registered. This includes the MLmodel file, model.pkl and the conda.yaml.\r\n",
        "run.register_model(model_name = 'my-model', model_path = 'model')\r\n",
        "\r\n",
        "# then view registered model in worksapce with aml studio"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Usage: ipykernel_launcher.py [options]\n",
            "\n",
            "ipykernel_launcher.py: error: no such option: -f\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "2",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
          ]
        }
      ],
      "execution_count": 18,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1621868622746
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.train.hyperdrive import RandomParameterSampling, BanditPolicy, HyperDriveConfig, PrimaryMetricGoal\r\n",
        "from azureml.train.hyperdrive import choice, loguniform"
      ],
      "outputs": [],
      "execution_count": 11,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1621848584669
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ps = RandomParameterSampling(\r\n",
        "    {\r\n",
        "        '--batch_size': choice(), # 8\r\n",
        "        '--hidden_size': choice(), # 128\r\n",
        "        '--layers': choice(), #2\r\n",
        "        '--iterations': choice() # 3\r\n",
        "    }\r\n",
        ")\r\n",
        "\r\n",
        "# BanditPolicy checks job every (evaluation_interval) number of iterations terminating the job if primary metric outside of slack_factor\r\n",
        "early_term_policy = BanditPolicy(evaluation_interval = 2, slack_factor = 0.1)\r\n",
        "\r\n",
        "# HyperDriveConfig\r\n",
        "hdc = HyperDriveConfig(estimator = est, hyperparameter_sampling = ps, \r\n",
        "                       policy = early_term_policy, primary_metric_name = 'Accuracy',\r\n",
        "                       primary_metric_goal = PrimaryMetricGoal.MAXIMIZE, \r\n",
        "                       max_total_runs = 20, max_concurrent_runs = 4)\r\n"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "HyperDriveConfigException",
          "evalue": "HyperDriveConfigException:\n\tMessage: Please specify an input for choice.\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"Please specify an input for choice.\",\n        \"details_uri\": \"https://docs.microsoft.com/en-us/python/api/azureml-train-core/azureml.train.hyperdrive.hyperdriveconfig?view=azure-ml-py\",\n        \"target\": \"options\",\n        \"inner_error\": {\n            \"code\": \"BadArgument\",\n            \"inner_error\": {\n                \"code\": \"ArgumentBlankOrEmpty\"\n            }\n        }\n    }\n}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHyperDriveConfigException\u001b[0m                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-bd5f4387ef17>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m ps = RandomParameterSampling(\n\u001b[1;32m      2\u001b[0m     {\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0;34m'--batch_size'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# 8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0;34m'--hidden_size'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# 128\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;34m'--layers'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m#2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/train/hyperdrive/parameter_expressions.py\u001b[0m in \u001b[0;36mchoice\u001b[0;34m(*options)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \"\"\"\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         raise HyperDriveConfigException._with_error(\n\u001b[0m\u001b[1;32m     36\u001b[0m             AzureMLError.create(\n\u001b[1;32m     37\u001b[0m                 \u001b[0mMissingChoiceValues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"options\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHyperDriveConfigException\u001b[0m: HyperDriveConfigException:\n\tMessage: Please specify an input for choice.\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"Please specify an input for choice.\",\n        \"details_uri\": \"https://docs.microsoft.com/en-us/python/api/azureml-train-core/azureml.train.hyperdrive.hyperdriveconfig?view=azure-ml-py\",\n        \"target\": \"options\",\n        \"inner_error\": {\n            \"code\": \"BadArgument\",\n            \"inner_error\": {\n                \"code\": \"ArgumentBlankOrEmpty\"\n            }\n        }\n    }\n}"
          ]
        }
      ],
      "execution_count": 12,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": true
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "tsir-rdkit-env",
      "language": "python",
      "display_name": "Python (tsir-rdkit-env)"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "tsir-rdkit-env"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}